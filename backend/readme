# e_TA backend
## File sturcture

backend/
│
├── env/                 # environment setting 
│   ├──          
│   ├── requirements.txt 
│   └── ...              
│
├── controller/          
│   ├── handleQuery.py   # call relative service 
│   └── service/    
│       ├── embedding/   # embedding model 
│       │    ├── src/            # data needed for embedding model 
│       │    ├── getAnswer.py    # get similar Q&A from database
│       │    └── voc2Doc.py      # model training
│       └── LLM/         # LLM API
│            ├── gpt.py          # call GPT 
│            └── llama2.py       # call llama2
│
├── app.py               # main file, run this to start server
└── README.md
# Devops
## Run conda envirment before run the program
```
conda activate DirRes #Mario's env
```
## Running backend program on the backend(always run)
```
nohup python3 app.py > output.log 2>&1 &
```
## Check the PID of the program occupying the certain port
```
lsof -i :PORT
```

