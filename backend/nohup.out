Traceback (most recent call last):
  File "/home/mario/DirectResearch/backend/app.py", line 1, in <module>
    from flask import Flask, request, jsonify
ModuleNotFoundError: No module named 'flask'
 * Serving Flask app 'app'
 * Debug mode: on
[31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on http://127.0.0.1:5000
[33mPress CTRL+C to quit[0m
 * Restarting with stat
 * Debugger is active!
 * Debugger PIN: 127-802-004
127.0.0.1 - - [09/Feb/2024 14:16:53] "POST /test HTTP/1.1" 200 -
127.0.0.1 - - [09/Feb/2024 14:17:05] "POST /test HTTP/1.1" 200 -
127.0.0.1 - - [09/Feb/2024 14:17:06] "POST /test HTTP/1.1" 200 -
127.0.0.1 - - [09/Feb/2024 14:17:34] "POST /test HTTP/1.1" 200 -
127.0.0.1 - - [09/Feb/2024 14:18:32] "[31m[1mPOST /test HTTP/1.1[0m" 400 -
127.0.0.1 - - [09/Feb/2024 14:20:00] "[31m[1mPOST /test HTTP/1.1[0m" 400 -
127.0.0.1 - - [09/Feb/2024 14:22:50] "POST /test HTTP/1.1" 200 -
127.0.0.1 - - [09/Feb/2024 14:29:29] "[35m[1mPOST /ask HTTP/1.1[0m" 500 -
Traceback (most recent call last):
  File "/home/mario/miniconda3/envs/DirRes/lib/python3.12/site-packages/flask/app.py", line 2552, in __call__
    return self.wsgi_app(environ, start_response)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mario/miniconda3/envs/DirRes/lib/python3.12/site-packages/flask/app.py", line 2532, in wsgi_app
    response = self.handle_exception(e)
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mario/miniconda3/envs/DirRes/lib/python3.12/site-packages/flask/app.py", line 2529, in wsgi_app
    response = self.full_dispatch_request()
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mario/miniconda3/envs/DirRes/lib/python3.12/site-packages/flask/app.py", line 1825, in full_dispatch_request
    rv = self.handle_user_exception(e)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mario/miniconda3/envs/DirRes/lib/python3.12/site-packages/flask/app.py", line 1823, in full_dispatch_request
    rv = self.dispatch_request()
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mario/miniconda3/envs/DirRes/lib/python3.12/site-packages/flask/app.py", line 1799, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mario/DirectResearch/backend/app.py", line 24, in answer_question
    answer = handleQuery(question)
             ^^^^^^^^^^^^^^^^^^^^^
  File "/home/mario/DirectResearch/backend/controller/handleQuery.py", line 22, in handleQuery
    result = query_GPT(final_prompt)
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mario/DirectResearch/backend/controller/service/LLM/gpt.py", line 5, in query_GPT
    client = OpenAI()
             ^^^^^^^^
  File "/home/mario/miniconda3/envs/DirRes/lib/python3.12/site-packages/openai/_client.py", line 98, in __init__
    raise OpenAIError(
openai.OpenAIError: The api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable
127.0.0.1 - - [09/Feb/2024 14:33:56] "[35m[1mPOST /ask HTTP/1.1[0m" 500 -
Traceback (most recent call last):
  File "/home/mario/miniconda3/envs/DirRes/lib/python3.12/site-packages/flask/app.py", line 2552, in __call__
    return self.wsgi_app(environ, start_response)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mario/miniconda3/envs/DirRes/lib/python3.12/site-packages/flask/app.py", line 2532, in wsgi_app
    response = self.handle_exception(e)
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mario/miniconda3/envs/DirRes/lib/python3.12/site-packages/flask/app.py", line 2529, in wsgi_app
    response = self.full_dispatch_request()
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mario/miniconda3/envs/DirRes/lib/python3.12/site-packages/flask/app.py", line 1825, in full_dispatch_request
    rv = self.handle_user_exception(e)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mario/miniconda3/envs/DirRes/lib/python3.12/site-packages/flask/app.py", line 1823, in full_dispatch_request
    rv = self.dispatch_request()
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mario/miniconda3/envs/DirRes/lib/python3.12/site-packages/flask/app.py", line 1799, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mario/DirectResearch/backend/app.py", line 24, in answer_question
    answer = handleQuery(question)
             ^^^^^^^^^^^^^^^^^^^^^
  File "/home/mario/DirectResearch/backend/controller/handleQuery.py", line 22, in handleQuery
    result = query_GPT(final_prompt)
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mario/DirectResearch/backend/controller/service/LLM/gpt.py", line 5, in query_GPT
    client = OpenAI()
             ^^^^^^^^
  File "/home/mario/miniconda3/envs/DirRes/lib/python3.12/site-packages/openai/_client.py", line 98, in __init__
    raise OpenAIError(
openai.OpenAIError: The api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable
127.0.0.1 - - [09/Feb/2024 14:36:35] "[35m[1mPOST /ask HTTP/1.1[0m" 500 -
Traceback (most recent call last):
  File "/home/mario/miniconda3/envs/DirRes/lib/python3.12/site-packages/flask/app.py", line 2552, in __call__
    return self.wsgi_app(environ, start_response)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mario/miniconda3/envs/DirRes/lib/python3.12/site-packages/flask/app.py", line 2532, in wsgi_app
    response = self.handle_exception(e)
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mario/miniconda3/envs/DirRes/lib/python3.12/site-packages/flask/app.py", line 2529, in wsgi_app
    response = self.full_dispatch_request()
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mario/miniconda3/envs/DirRes/lib/python3.12/site-packages/flask/app.py", line 1825, in full_dispatch_request
    rv = self.handle_user_exception(e)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mario/miniconda3/envs/DirRes/lib/python3.12/site-packages/flask/app.py", line 1823, in full_dispatch_request
    rv = self.dispatch_request()
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mario/miniconda3/envs/DirRes/lib/python3.12/site-packages/flask/app.py", line 1799, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mario/DirectResearch/backend/app.py", line 24, in answer_question
    answer = handleQuery(question)
             ^^^^^^^^^^^^^^^^^^^^^
  File "/home/mario/DirectResearch/backend/controller/handleQuery.py", line 22, in handleQuery
    result = query_GPT(final_prompt)
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mario/DirectResearch/backend/controller/service/LLM/gpt.py", line 5, in query_GPT
    client = OpenAI()
             ^^^^^^^^
  File "/home/mario/miniconda3/envs/DirRes/lib/python3.12/site-packages/openai/_client.py", line 98, in __init__
    raise OpenAIError(
openai.OpenAIError: The api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable
127.0.0.1 - - [09/Feb/2024 14:36:40] "[35m[1mPOST /ask HTTP/1.1[0m" 500 -
Traceback (most recent call last):
  File "/home/mario/miniconda3/envs/DirRes/lib/python3.12/site-packages/flask/app.py", line 2552, in __call__
    return self.wsgi_app(environ, start_response)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mario/miniconda3/envs/DirRes/lib/python3.12/site-packages/flask/app.py", line 2532, in wsgi_app
    response = self.handle_exception(e)
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mario/miniconda3/envs/DirRes/lib/python3.12/site-packages/flask/app.py", line 2529, in wsgi_app
    response = self.full_dispatch_request()
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mario/miniconda3/envs/DirRes/lib/python3.12/site-packages/flask/app.py", line 1825, in full_dispatch_request
    rv = self.handle_user_exception(e)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mario/miniconda3/envs/DirRes/lib/python3.12/site-packages/flask/app.py", line 1823, in full_dispatch_request
    rv = self.dispatch_request()
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mario/miniconda3/envs/DirRes/lib/python3.12/site-packages/flask/app.py", line 1799, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mario/DirectResearch/backend/app.py", line 24, in answer_question
    answer = handleQuery(question)
             ^^^^^^^^^^^^^^^^^^^^^
  File "/home/mario/DirectResearch/backend/controller/handleQuery.py", line 22, in handleQuery
    result = query_GPT(final_prompt)
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mario/DirectResearch/backend/controller/service/LLM/gpt.py", line 5, in query_GPT
    client = OpenAI()
             ^^^^^^^^
  File "/home/mario/miniconda3/envs/DirRes/lib/python3.12/site-packages/openai/_client.py", line 98, in __init__
    raise OpenAIError(
openai.OpenAIError: The api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable
127.0.0.1 - - [09/Feb/2024 14:37:25] "[35m[1mPOST /ask HTTP/1.1[0m" 500 -
Traceback (most recent call last):
  File "/home/mario/miniconda3/envs/DirRes/lib/python3.12/site-packages/flask/app.py", line 2552, in __call__
    return self.wsgi_app(environ, start_response)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mario/miniconda3/envs/DirRes/lib/python3.12/site-packages/flask/app.py", line 2532, in wsgi_app
    response = self.handle_exception(e)
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mario/miniconda3/envs/DirRes/lib/python3.12/site-packages/flask/app.py", line 2529, in wsgi_app
    response = self.full_dispatch_request()
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mario/miniconda3/envs/DirRes/lib/python3.12/site-packages/flask/app.py", line 1825, in full_dispatch_request
    rv = self.handle_user_exception(e)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mario/miniconda3/envs/DirRes/lib/python3.12/site-packages/flask/app.py", line 1823, in full_dispatch_request
    rv = self.dispatch_request()
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mario/miniconda3/envs/DirRes/lib/python3.12/site-packages/flask/app.py", line 1799, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mario/DirectResearch/backend/app.py", line 24, in answer_question
    answer = handleQuery(question)
             ^^^^^^^^^^^^^^^^^^^^^
  File "/home/mario/DirectResearch/backend/controller/handleQuery.py", line 22, in handleQuery
    result = query_GPT(final_prompt)
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mario/DirectResearch/backend/controller/service/LLM/gpt.py", line 5, in query_GPT
    client = OpenAI()
             ^^^^^^^^
  File "/home/mario/miniconda3/envs/DirRes/lib/python3.12/site-packages/openai/_client.py", line 98, in __init__
    raise OpenAIError(
openai.OpenAIError: The api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable
127.0.0.1 - - [09/Feb/2024 16:14:31] "[33mGET / HTTP/1.1[0m" 404 -
127.0.0.1 - - [09/Feb/2024 17:57:13] code 400, message Bad request version ('Ã€\x14Ã€')
127.0.0.1 - - [09/Feb/2024 17:57:13] "[31m[1m\x16\x03\x01\x00{\x01\x00\x00w\x03\x03\x83Ã‰E\x07Ã„\x1aÃ]\x83Ã·\x8c\x84\x1f\x02Â¦\x9dM3~-kB*Ã€ÃŠX\x14Ã¤Ã\x93s)\x00\x00\x1aÃ€/Ã€+Ã€\x11Ã€\x07Ã€\x13Ã€\x09Ã€\x14Ã€[0m" 400 -
127.0.0.1 - - [09/Feb/2024 17:57:14] code 400, message Bad request version ('Ã€\x14Ã€')
127.0.0.1 - - [09/Feb/2024 17:57:14] "[31m[1m\x16\x03\x01\x00{\x01\x00\x00w\x03\x03g\x98\x8d\x84Ãš\x07\x1bÂºÃ·Â¹UÂ¬\x9dÃ½Ã•]GÃ…\x15Ã­Â©\x1d8KÂ±\x89Ã›Ã\x0f\x882+\x00\x00\x1aÃ€/Ã€+Ã€\x11Ã€\x07Ã€\x13Ã€\x09Ã€\x14Ã€[0m" 400 -
127.0.0.1 - - [09/Feb/2024 17:57:14] "[33mGET / HTTP/1.1[0m" 404 -
127.0.0.1 - - [09/Feb/2024 19:17:09] "[33mGET /v2/ HTTP/1.1[0m" 404 -
127.0.0.1 - - [10/Feb/2024 00:22:31] code 400, message Bad request version ('Ã€\x14Ã€')
127.0.0.1 - - [10/Feb/2024 00:22:31] "[31m[1m\x16\x03\x01\x00Ã®\x01\x00\x00Ãª\x03\x03\x88Â·i\x04Ã¹]\x8cÂ±\x92\x7fÃH'Ã¹\x91\x10Â¡\x95Ã€\x1cD\x1dÂ¼OÃ‹6TÂ²ÃEÂ¿l Ã•Â¹Ã¶\x17JiÂ¯Ã…Ã™Ã–S@\x1ckÃÂ Â¬\x1a,Ã¨\x02eÃ°\x7f!Ã‰Ã SÂ±}Â¶\x95\x00&ÃŒÂ¨ÃŒÂ©Ã€/Ã€0Ã€+Ã€,Ã€\x13Ã€\x09Ã€\x14Ã€[0m" 400 -
127.0.0.1 - - [10/Feb/2024 00:22:34] "[33mGET / HTTP/1.1[0m" 404 -
127.0.0.1 - - [10/Feb/2024 00:22:37] "[33mGET / HTTP/1.1[0m" 404 -
127.0.0.1 - - [10/Feb/2024 00:22:38] code 505, message Invalid HTTP version (2.0)
127.0.0.1 - - [10/Feb/2024 00:22:38] "[35m[1mPRI * HTTP/2.0[0m" 505 -
127.0.0.1 - - [10/Feb/2024 08:39:38] code 400, message Bad request version ('Ã€\x14Ã€')
127.0.0.1 - - [10/Feb/2024 08:39:38] "[31m[1m\x16\x03\x01\x00{\x01\x00\x00w\x03\x03Ã„9y\x88ÂºQV\x80Â®\x99>Ã\\o\x0d\x9fR\x86Ã‘\x90\x92Ã¬\x97\x95}Â²Ã¬Ã¡Â¬>Â­\x81\x00\x00\x1aÃ€/Ã€+Ã€\x11Ã€\x07Ã€\x13Ã€\x09Ã€\x14Ã€[0m" 400 -
127.0.0.1 - - [10/Feb/2024 08:39:38] code 400, message Bad request version ('Ã€\x14Ã€')
127.0.0.1 - - [10/Feb/2024 08:39:38] "[31m[1m\x16\x03\x01\x00{\x01\x00\x00w\x03\x03"5lG=\x90x\x19Â§2Â¯HÃ˜7Ã–=Ã—t\x97\x8e\x1c-"ÃªÃl\x7fÂ¿,\x0cÂº\x02\x00\x00\x1aÃ€/Ã€+Ã€\x11Ã€\x07Ã€\x13Ã€\x09Ã€\x14Ã€[0m" 400 -
127.0.0.1 - - [10/Feb/2024 08:39:39] "[33mGET / HTTP/1.1[0m" 404 -
127.0.0.1 - - [10/Feb/2024 16:18:12] code 400, message Bad HTTP/0.9 request type ('\x16\x03\x01\x00{\x01\x00\x00w\x03\x034Â¬ÂªÃ„Ã\x02Ã¶7\x8d@\x05Ã¯?J\x8e50\x93ÃÃ§Â·Ã¾Âº\x8eÃ†x8]Ã°Â§Ã¦Ã‰\x00\x00\x1aÃ€/Ã€+Ã€\x11Ã€\x07Ã€\x13Ã€')
127.0.0.1 - - [10/Feb/2024 16:18:12] "[31m[1m\x16\x03\x01\x00{\x01\x00\x00w\x03\x034Â¬ÂªÃ„Ã\x02Ã¶7\x8d@\x05Ã¯?J\x8e50\x93ÃÃ§Â·Ã¾Âº\x8eÃ†x8]Ã°Â§Ã¦Ã‰\x00\x00\x1aÃ€/Ã€+Ã€\x11Ã€\x07Ã€\x13Ã€\x09Ã€\x14Ã€[0m" 400 -
127.0.0.1 - - [10/Feb/2024 16:18:13] code 400, message Bad request version ('Ã€\x14Ã€')
127.0.0.1 - - [10/Feb/2024 16:18:13] "[31m[1m\x16\x03\x01\x00{\x01\x00\x00w\x03\x03\x9e\x1b \x93Ã›Ã¾Â¦7\x94Ã™JP\x8f\x1cÂº\x915\x8f\x8c\x87\x98Â§zÃ«Â¨\x0dÃ\x99Ã±\x19~Ã¿\x00\x00\x1aÃ€/Ã€+Ã€\x11Ã€\x07Ã€\x13Ã€\x09Ã€\x14Ã€[0m" 400 -
127.0.0.1 - - [10/Feb/2024 16:18:13] "[33mGET / HTTP/1.1[0m" 404 -
127.0.0.1 - - [10/Feb/2024 17:49:38] "[33mGET / HTTP/1.1[0m" 404 -
127.0.0.1 - - [10/Feb/2024 17:55:44] code 400, message Bad request version ('Ã€\x14Ã€')
127.0.0.1 - - [10/Feb/2024 17:55:44] "[31m[1m\x16\x03\x01\x00Ã®\x01\x00\x00Ãª\x03\x03\x99\x80\x88Ã˜k$Â¸Ã¡OÃÃ®Ã¦\x92"\x858!Ã¹oÂ·\x88;\x9e\x9a\x82k|Ã°xÃ•\x12Ã† Â§#0_Ã§\x0dÃ§%Ã‚:Âµ|\x81\x82\x00UÂ¥-AÃ‚)Ãƒ\x17?9Ã¬\x13AÂ¥rÃ¨Â¥\x00&ÃŒÂ¨ÃŒÂ©Ã€/Ã€0Ã€+Ã€,Ã€\x13Ã€\x09Ã€\x14Ã€[0m" 400 -
127.0.0.1 - - [10/Feb/2024 17:55:47] "[33mGET / HTTP/1.1[0m" 404 -
127.0.0.1 - - [10/Feb/2024 17:55:51] "[33mGET / HTTP/1.1[0m" 404 -
127.0.0.1 - - [10/Feb/2024 17:55:51] code 505, message Invalid HTTP version (2.0)
127.0.0.1 - - [10/Feb/2024 17:55:51] "[35m[1mPRI * HTTP/2.0[0m" 505 -
127.0.0.1 - - [10/Feb/2024 18:41:04] code 400, message Bad request version ('Ã€\x14Ã€')
127.0.0.1 - - [10/Feb/2024 18:41:04] "[31m[1m\x16\x03\x01\x00Ã®\x01\x00\x00Ãª\x03\x03Ãµ0P\x7fBÃ\x0dÃ–.\x00E1LÃÃ‰R<Â³ghÂ¶bÃ½4\x88\x11'\x91\x1e\x9eÃ³v MÃ¢&*t\x9d|Ã€\x97'ÃŠÃ•Ã‰Ã­\x80Â½\x9fÂ±Â·Â«X<iÃš\x940Â·Â½Â¹<Â«\x9f\x00&ÃŒÂ¨ÃŒÂ©Ã€/Ã€0Ã€+Ã€,Ã€\x13Ã€\x09Ã€\x14Ã€[0m" 400 -
127.0.0.1 - - [10/Feb/2024 18:41:07] "[33mGET / HTTP/1.1[0m" 404 -
127.0.0.1 - - [10/Feb/2024 18:41:10] "[33mGET / HTTP/1.1[0m" 404 -
127.0.0.1 - - [10/Feb/2024 18:41:10] code 505, message Invalid HTTP version (2.0)
127.0.0.1 - - [10/Feb/2024 18:41:10] "[35m[1mPRI * HTTP/2.0[0m" 505 -
127.0.0.1 - - [10/Feb/2024 19:58:14] code 400, message Bad HTTP/0.9 request type ('\x16\x03\x01\x01Ã¼\x01\x00\x01Ã¸\x03\x03-Â¦DÃµÃ½-\x90Âª_\x98Ã¹')
127.0.0.1 - - [10/Feb/2024 19:58:14] "[31m[1m\x16\x03\x01\x01Ã¼\x01\x00\x01Ã¸\x03\x03-Â¦DÃµÃ½-\x90Âª_\x98Ã¹\x1e\x00\x9e\x842Ã¨\x04Ã\x05\x93ÃˆÂ¡Â¤+YÃ­Ã´IÃ¥Ã\x03\x00\x01<ÃŒ\x14ÃŒ\x13ÃŒ\x15Ã€0Ã€,Ã€(Ã€$Ã€\x14Ã€[0m" 400 -
127.0.0.1 - - [10/Feb/2024 20:02:22] code 400, message Bad request version ('\x00\x9eÃŒÂ¨ÃŒÂª\x003\x00=\x00\x16Ã€')
127.0.0.1 - - [10/Feb/2024 20:02:22] "[31m[1m\x16\x03\x01\x01\x17\x01\x00\x01\x13\x03\x03UÃ„ÃŒ\x13%Ã³Ã‰\x97\x0b\x96\x9aÃ¬\x82\x8d\x88.l\x81\x8eÂ§/Ã¿\x05Ã…`AÃbwÃ»Â¨\x82 Ãªj\x1eÃ _ZI|Âµ\x8e\x80Â¯\x80ÃŠÂ·\x8bÃ•%B\x87Ã‚Ãh\x97~Ã¢IÃ…\x7fsTÂµ\x004ÃŒÂ¨ÃŒÂ©Ã€/Ã€0Ã€+Ã€,Ã€\x09\x00\x9eÃŒÂ¨ÃŒÂª\x003\x00=\x00\x16Ã€[0m" 400 -
127.0.0.1 - - [10/Feb/2024 20:02:33] "[33mGET / HTTP/1.1[0m" 404 -
127.0.0.1 - - [10/Feb/2024 20:02:33] "[33mGET /favicon.ico HTTP/1.1[0m" 404 -
127.0.0.1 - - [10/Feb/2024 20:02:34] "[33mGET /robots.txt HTTP/1.1[0m" 404 -
127.0.0.1 - - [10/Feb/2024 20:02:34] "[33mGET /sitemap.xml HTTP/1.1[0m" 404 -
127.0.0.1 - - [10/Feb/2024 20:11:51] "[33mGET / HTTP/1.0[0m" 404 -
127.0.0.1 - - [10/Feb/2024 21:53:21] "[33mGET / HTTP/1.1[0m" 404 -
127.0.0.1 - - [10/Feb/2024 22:23:48] "POST /test HTTP/1.1" 200 -
127.0.0.1 - - [10/Feb/2024 23:15:37] "[35m[1mPOST /ask HTTP/1.1[0m" 500 -
Traceback (most recent call last):
  File "/home/mario/miniconda3/envs/DirRes/lib/python3.12/site-packages/flask/app.py", line 2552, in __call__
    return self.wsgi_app(environ, start_response)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mario/miniconda3/envs/DirRes/lib/python3.12/site-packages/flask/app.py", line 2532, in wsgi_app
    response = self.handle_exception(e)
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mario/miniconda3/envs/DirRes/lib/python3.12/site-packages/flask/app.py", line 2529, in wsgi_app
    response = self.full_dispatch_request()
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mario/miniconda3/envs/DirRes/lib/python3.12/site-packages/flask/app.py", line 1825, in full_dispatch_request
    rv = self.handle_user_exception(e)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mario/miniconda3/envs/DirRes/lib/python3.12/site-packages/flask/app.py", line 1823, in full_dispatch_request
    rv = self.dispatch_request()
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mario/miniconda3/envs/DirRes/lib/python3.12/site-packages/flask/app.py", line 1799, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mario/DirectResearch/backend/app.py", line 24, in answer_question
    answer = handleQuery(question)
             ^^^^^^^^^^^^^^^^^^^^^
  File "/home/mario/DirectResearch/backend/controller/handleQuery.py", line 22, in handleQuery
    result = query_GPT(final_prompt)
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mario/DirectResearch/backend/controller/service/LLM/gpt.py", line 5, in query_GPT
    client = OpenAI()
             ^^^^^^^^
  File "/home/mario/miniconda3/envs/DirRes/lib/python3.12/site-packages/openai/_client.py", line 98, in __init__
    raise OpenAIError(
openai.OpenAIError: The api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable
127.0.0.1 - - [10/Feb/2024 23:18:20] "POST /test HTTP/1.1" 200 -
127.0.0.1 - - [10/Feb/2024 23:18:21] "POST /test HTTP/1.1" 200 -
127.0.0.1 - - [10/Feb/2024 23:18:54] "POST /test HTTP/1.1" 200 -
127.0.0.1 - - [10/Feb/2024 23:19:15] "POST /test HTTP/1.1" 200 -
